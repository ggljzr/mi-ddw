{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cranfield dataset processing\n",
    "\n",
    "This notebook creates vector space model for documents and queries contained in [Cranfield](http://ir.dcs.gla.ac.uk/resources/test_collections/cran/) collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions. `get_top_n()` simply returns indices of top ten relevant documents for each query. `get_precision()` returns precision, recall and f-score for a query (represented by query index and top ten documents retrieved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n(matrix, n=10):\n",
    "\treturn np.array([ matrix[i].argsort()[-n:][::-1]+1 for i in range(225)])\n",
    "\n",
    "def get_precision(query_index, top_retrieved):\n",
    "\trelevant = []\n",
    "\twith open('cranfield/r/{}.txt'.format(query_index)) as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\trelevant.append(int(line))\n",
    "\n",
    "\ttp = 0\n",
    "\tfn = 0\n",
    "\tfp = 0\n",
    "\n",
    "\tfor doc in relevant:\n",
    "\t\tif doc in retrieved:\n",
    "\t\t\ttp += 1\n",
    "\t\telse:\n",
    "\t\t\tfn += 1 \n",
    "\n",
    "\tfor doc in retrieved:\n",
    "\t\tif doc not in relevant:\n",
    "\t\t\tfp += 1\n",
    "\n",
    "\tp = tp / (tp + fp)\n",
    "\tr = tp / (tp + fn)\n",
    "\tf = 2 * ((p * r)/(p + r))\n",
    "\n",
    "\treturn p, r, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare corpus of documents and queries for processing. Note that `corpus[:1400]` contains documents and `corpus[1400:]` contains queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for d in range(1400):\n",
    "    f = open(\"cranfield/d/\"+str(d+1)+\".txt\")\n",
    "    corpus.append(f.read())\n",
    "    f.close()\n",
    "for q in range(225):\n",
    "    f = open(\"cranfield/q/\"+str(q+1)+\".txt\")\n",
    "    corpus.append(f.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of different vectorizers we are going to use to create vector space model.\n",
    "* TFIDF vectorizer -- calculates [TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) score for each document or query\n",
    "* Count vectorizer -- counts term in each document or query\n",
    "* Binary vectorizer -- 1 if term is present in document/query, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorizer = CountVectorizer()\n",
    "binary_vectorizer = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices with dimensions (1625 -- number of documents and queries, 20679 -- total number of terms) for each vectorizer. Matrix rows are vector of given vector space models (each row represent document or query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "count_matrix = count_vectorizer.fit_transform(corpus)\n",
    "bin_matrix = binary_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similarity between queries and documents using given vector space model (TFIDF, count, binary) and distance measure (cosine similiarity, euclidean distance). Each matrix has dimensions (225, 1400), each element represents similarity betweent one query and one document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_tfdif_cos = np.array(cosine_similarity(tfidf_matrix[1400:], tfidf_matrix[:1400]))\n",
    "r_tfdif_euc = np.array(pairwise_distances(tfidf_matrix[1400:], tfidf_matrix[:1400]))\n",
    "\n",
    "r_count_cos = np.array(cosine_similarity(count_matrix[1400:], count_matrix[:1400]))\n",
    "r_count_euc = np.array(pairwise_distances(count_matrix[1400:], count_matrix[:1400]))\n",
    "\n",
    "r_bin_cos = np.array(cosine_similarity(bin_matrix[1400:], bin_matrix[:1400]))\n",
    "r_bin_euc = np.array(pairwise_distances(bin_matrix[1400:], bin_matrix[:1400]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of 10 most relevant documents for each query using given vector space model and distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_relevant_tfdif_cos = get_top_n(r_tfdif_cos)\n",
    "top_relevant_tfdif_euc = get_top_n(r_tfdif_euc)\n",
    "\n",
    "top_relevant_count_cos = get_top_n(r_count_cos)\n",
    "top_relevant_count_euc = get_top_n(r_count_euc)\n",
    "\n",
    "top_relevant_bin_cos = get_top_n(r_bin_cos)\n",
    "top_relevant_bin_euc = get_top_n(r_bin_euc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
